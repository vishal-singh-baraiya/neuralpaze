import type { ModelTemplateCategory } from "../types"

export const modelTemplates: ModelTemplateCategory = {
  "Basic Networks": [
    {
      id: "mlp-classifier",
      name: "MLP Classifier",
      description:
        "A simple yet effective multi-layer perceptron perfect for tabular data classification. Features dropout regularization and ReLU activations for robust learning.",
      category: "Basic Networks",
      components: [
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 784, output_size: 256, bias: true },
          description: "Input layer - processes raw features",
        },
        {
          type: "ReLU",
          icon: "â†—",
          color: "#06B6D4",
          params: {},
          description: "Non-linear activation function",
        },
        {
          type: "Dropout",
          icon: "â—Š",
          color: "#F59E0B",
          params: { p: 0.2 },
          description: "Prevents overfitting during training",
        },
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 256, output_size: 128, bias: true },
          description: "Hidden layer - learns feature representations",
        },
        {
          type: "ReLU",
          icon: "â†—",
          color: "#06B6D4",
          params: {},
          description: "Non-linear activation function",
        },
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 128, output_size: 10, bias: true },
          description: "Output layer - produces class predictions",
        },
        {
          type: "Softmax",
          icon: "âˆ‘",
          color: "#06B6D4",
          params: { dim: -1 },
          description: "Converts logits to probabilities",
        },
      ],
      connections: [
        { from: 0, to: 1, fromPort: "output", toPort: "input" },
        { from: 1, to: 2, fromPort: "output", toPort: "input" },
        { from: 2, to: 3, fromPort: "output", toPort: "input" },
        { from: 3, to: 4, fromPort: "output", toPort: "input" },
        { from: 4, to: 5, fromPort: "output", toPort: "input" },
        { from: 5, to: 6, fromPort: "output", toPort: "input" },
      ],
    },
    {
      id: "cnn-image",
      name: "CNN Image Classifier",
      description:
        "Convolutional neural network optimized for image recognition tasks. Uses spatial convolutions to detect features and patterns in visual data.",
      category: "Basic Networks",
      components: [
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 3, out_channels: 32, kernel_size: 3, stride: 1, padding: 1 },
          description: "Detects low-level features like edges",
        },
        {
          type: "ReLU",
          icon: "â†—",
          color: "#06B6D4",
          params: {},
          description: "Non-linear activation function",
        },
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 32, out_channels: 64, kernel_size: 3, stride: 1, padding: 1 },
          description: "Detects higher-level feature combinations",
        },
        {
          type: "ReLU",
          icon: "â†—",
          color: "#06B6D4",
          params: {},
          description: "Non-linear activation function",
        },
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 64 * 7 * 7, output_size: 128, bias: true },
          description: "Flattens and processes spatial features",
        },
        {
          type: "ReLU",
          icon: "â†—",
          color: "#06B6D4",
          params: {},
          description: "Non-linear activation function",
        },
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 128, output_size: 10, bias: true },
          description: "Final classification layer",
        },
      ],
      connections: [
        { from: 0, to: 1, fromPort: "output", toPort: "input" },
        { from: 1, to: 2, fromPort: "output", toPort: "input" },
        { from: 2, to: 3, fromPort: "output", toPort: "input" },
        { from: 3, to: 4, fromPort: "output", toPort: "input" },
        { from: 4, to: 5, fromPort: "output", toPort: "input" },
        { from: 5, to: 6, fromPort: "output", toPort: "input" },
      ],
    },
  ],
  Transformers: [
    {
      id: "transformer-encoder",
      name: "Transformer Encoder",
      description:
        "Standard transformer encoder architecture with multi-head self-attention. Perfect for sequence modeling, text classification, and feature extraction tasks.",
      category: "Transformers",
      components: [
        {
          type: "Embedding",
          icon: "âŠž",
          color: "#8B5CF6",
          params: { vocab_size: 30000, embed_dim: 512, padding_idx: 0 },
          description: "Converts tokens to dense vectors",
        },
        {
          type: "TransformerBlock",
          icon: "âŠž",
          color: "#7C3AED",
          params: { d_model: 512, num_heads: 8, d_ff: 2048, dropout: 0.1 },
          description: "Self-attention and feed-forward layers",
        },
        {
          type: "TransformerBlock",
          icon: "âŠž",
          color: "#7C3AED",
          params: { d_model: 512, num_heads: 8, d_ff: 2048, dropout: 0.1 },
          description: "Second transformer layer for deeper understanding",
        },
        {
          type: "TransformerBlock",
          icon: "âŠž",
          color: "#7C3AED",
          params: { d_model: 512, num_heads: 8, d_ff: 2048, dropout: 0.1 },
          description: "Third transformer layer for complex patterns",
        },
        {
          type: "LayerNorm",
          icon: "â‰¡",
          color: "#EF4444",
          params: { normalized_shape: 512, eps: 1e-5 },
          description: "Stabilizes training and improves convergence",
        },
      ],
      connections: [
        { from: 0, to: 1, fromPort: "output", toPort: "input" },
        { from: 1, to: 2, fromPort: "output", toPort: "input" },
        { from: 2, to: 3, fromPort: "output", toPort: "input" },
        { from: 3, to: 4, fromPort: "output", toPort: "input" },
      ],
    },
    {
      id: "gpt-decoder",
      name: "GPT Decoder",
      description:
        "GPT-style decoder-only transformer for autoregressive language modeling. Ideal for text generation, completion, and conversational AI applications.",
      category: "Transformers",
      components: [
        {
          type: "Embedding",
          icon: "âŠž",
          color: "#8B5CF6",
          params: { vocab_size: 50000, embed_dim: 768, padding_idx: 0 },
          description: "Token embeddings with positional encoding",
        },
        {
          type: "GPTBlock",
          icon: "ðŸ¤–",
          color: "#7C3AED",
          params: { d_model: 768, num_heads: 12, d_ff: 3072, dropout: 0.1 },
          description: "Causal self-attention for autoregressive modeling",
        },
        {
          type: "GPTBlock",
          icon: "ðŸ¤–",
          color: "#7C3AED",
          params: { d_model: 768, num_heads: 12, d_ff: 3072, dropout: 0.1 },
          description: "Second GPT block for deeper language understanding",
        },
        {
          type: "GPTBlock",
          icon: "ðŸ¤–",
          color: "#7C3AED",
          params: { d_model: 768, num_heads: 12, d_ff: 3072, dropout: 0.1 },
          description: "Third GPT block for complex language patterns",
        },
        {
          type: "LayerNorm",
          icon: "â‰¡",
          color: "#EF4444",
          params: { normalized_shape: 768, eps: 1e-5 },
          description: "Final layer normalization",
        },
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 768, output_size: 50000, bias: false },
          description: "Projects to vocabulary for next token prediction",
        },
      ],
      connections: [
        { from: 0, to: 1, fromPort: "output", toPort: "input" },
        { from: 1, to: 2, fromPort: "output", toPort: "input" },
        { from: 2, to: 3, fromPort: "output", toPort: "input" },
        { from: 3, to: 4, fromPort: "output", toPort: "input" },
        { from: 4, to: 5, fromPort: "output", toPort: "input" },
      ],
    },
  ],
  "Advanced Architectures": [
    {
      id: "resnet-block",
      name: "ResNet Block",
      description:
        "Residual network building block that enables training of very deep networks. Skip connections help gradients flow and prevent vanishing gradient problems.",
      category: "Advanced Architectures",
      components: [
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 64, out_channels: 64, kernel_size: 3, stride: 1, padding: 1 },
          description: "First convolution in residual path",
        },
        {
          type: "BatchNorm",
          icon: "â‰ˆ",
          color: "#EF4444",
          params: { num_features: 64, eps: 1e-5, momentum: 0.1 },
          description: "Normalizes activations for stable training",
        },
        {
          type: "ReLU",
          icon: "â†—",
          color: "#06B6D4",
          params: {},
          description: "Non-linear activation function",
        },
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 64, out_channels: 64, kernel_size: 3, stride: 1, padding: 1 },
          description: "Second convolution in residual path",
        },
        {
          type: "BatchNorm",
          icon: "â‰ˆ",
          color: "#EF4444",
          params: { num_features: 64, eps: 1e-5, momentum: 0.1 },
          description: "Second batch normalization layer",
        },
        {
          type: "Residual",
          icon: "+",
          color: "#F97316",
          params: {},
          description: "Skip connection for gradient flow",
        },
        {
          type: "ReLU",
          icon: "â†—",
          color: "#06B6D4",
          params: {},
          description: "Final activation after residual addition",
        },
      ],
      connections: [
        { from: 0, to: 1, fromPort: "output", toPort: "input" },
        { from: 1, to: 2, fromPort: "output", toPort: "input" },
        { from: 2, to: 3, fromPort: "output", toPort: "input" },
        { from: 3, to: 4, fromPort: "output", toPort: "input" },
        { from: 4, to: 5, fromPort: "output", toPort: "input" },
        { from: 0, to: 5, fromPort: "output", toPort: "input" },
        { from: 5, to: 6, fromPort: "output", toPort: "input" },
      ],
    },
    {
      id: "moe-layer",
      name: "Mixture of Experts",
      description:
        "Sparse mixture of experts layer that routes inputs to specialized expert networks. Enables scaling model capacity while maintaining computational efficiency.",
      category: "Advanced Architectures",
      components: [
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 1024, output_size: 1024, bias: true },
          description: "Input projection for expert routing",
        },
        {
          type: "MixtureOfExperts",
          icon: "ðŸ”€",
          color: "#F97316",
          params: { d_model: 1024, num_experts: 8, top_k: 2, d_ff: 4096 },
          description: "Routes to top-k experts based on input",
        },
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 1024, output_size: 1024, bias: true },
          description: "Output projection after expert combination",
        },
        {
          type: "Residual",
          icon: "+",
          color: "#F97316",
          params: {},
          description: "Skip connection around MoE layer",
        },
        {
          type: "LayerNorm",
          icon: "â‰¡",
          color: "#EF4444",
          params: { normalized_shape: 1024, eps: 1e-5 },
          description: "Post-normalization for stability",
        },
      ],
      connections: [
        { from: 0, to: 1, fromPort: "output", toPort: "input" },
        { from: 1, to: 2, fromPort: "output", toPort: "input" },
        { from: 2, to: 3, fromPort: "output", toPort: "input" },
        { from: 0, to: 3, fromPort: "output", toPort: "input" },
        { from: 3, to: 4, fromPort: "output", toPort: "input" },
      ],
    },
  ],
  "Generative Models": [
    {
      id: "vae-encoder",
      name: "VAE Encoder",
      description:
        "Variational autoencoder encoder that learns a probabilistic latent representation. Essential for generative modeling and representation learning.",
      category: "Generative Models",
      components: [
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 3, out_channels: 32, kernel_size: 3, stride: 2, padding: 1 },
          description: "Downsamples input while extracting features",
        },
        {
          type: "ReLU",
          icon: "â†—",
          color: "#06B6D4",
          params: {},
          description: "Non-linear activation function",
        },
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 32, out_channels: 64, kernel_size: 3, stride: 2, padding: 1 },
          description: "Further downsampling and feature extraction",
        },
        {
          type: "ReLU",
          icon: "â†—",
          color: "#06B6D4",
          params: {},
          description: "Non-linear activation function",
        },
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 64 * 7 * 7, output_size: 256, bias: true },
          description: "Flattens spatial features to dense representation",
        },
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 256, output_size: 32, bias: true },
          description: "Outputs mean of latent distribution",
        },
        {
          type: "Linear",
          icon: "â– ",
          color: "#3B82F6",
          params: { input_size: 256, output_size: 32, bias: true },
          description: "Outputs log variance of latent distribution",
        },
      ],
      connections: [
        { from: 0, to: 1, fromPort: "output", toPort: "input" },
        { from: 1, to: 2, fromPort: "output", toPort: "input" },
        { from: 2, to: 3, fromPort: "output", toPort: "input" },
        { from: 3, to: 4, fromPort: "output", toPort: "input" },
        { from: 4, to: 5, fromPort: "output", toPort: "input" },
        { from: 4, to: 6, fromPort: "output", toPort: "input" },
      ],
    },
    {
      id: "diffusion-unet",
      name: "Diffusion UNet",
      description:
        "U-Net architecture optimized for diffusion models. Features skip connections and symmetric encoder-decoder structure for high-quality image generation.",
      category: "Generative Models",
      components: [
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 3, out_channels: 64, kernel_size: 3, stride: 1, padding: 1 },
          description: "Initial feature extraction from noisy input",
        },
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 64, out_channels: 128, kernel_size: 3, stride: 2, padding: 1 },
          description: "Encoder: downsamples and increases channels",
        },
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 128, out_channels: 256, kernel_size: 3, stride: 2, padding: 1 },
          description: "Encoder: further compression and feature extraction",
        },
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 256, out_channels: 256, kernel_size: 3, stride: 1, padding: 1 },
          description: "Bottleneck: processes compressed representation",
        },
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 256, out_channels: 128, kernel_size: 3, stride: 1, padding: 1 },
          description: "Decoder: begins upsampling process",
        },
        {
          type: "Concatenate",
          icon: "||",
          color: "#F97316",
          params: { dim: 1 },
          description: "Skip connection from encoder level 2",
        },
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 256, out_channels: 64, kernel_size: 3, stride: 1, padding: 1 },
          description: "Decoder: continues upsampling with skip info",
        },
        {
          type: "Concatenate",
          icon: "||",
          color: "#F97316",
          params: { dim: 1 },
          description: "Skip connection from encoder level 1",
        },
        {
          type: "Conv2D",
          icon: "â–¦",
          color: "#10B981",
          params: { in_channels: 128, out_channels: 3, kernel_size: 3, stride: 1, padding: 1 },
          description: "Final layer: outputs denoised image",
        },
      ],
      connections: [
        { from: 0, to: 1, fromPort: "output", toPort: "input" },
        { from: 1, to: 2, fromPort: "output", toPort: "input" },
        { from: 2, to: 3, fromPort: "output", toPort: "input" },
        { from: 3, to: 4, fromPort: "output", toPort: "input" },
        { from: 4, to: 5, fromPort: "output", toPort: "input" },
        { from: 2, to: 5, fromPort: "output", toPort: "input" },
        { from: 5, to: 6, fromPort: "output", toPort: "input" },
        { from: 6, to: 7, fromPort: "output", toPort: "input" },
        { from: 1, to: 7, fromPort: "output", toPort: "input" },
        { from: 7, to: 8, fromPort: "output", toPort: "input" },
      ],
    },
  ],
}
